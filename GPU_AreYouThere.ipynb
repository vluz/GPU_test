{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Vic's \"Are you there GPU?\"\n",
        "\n",
        "Run each cell in sequence\n"
      ],
      "metadata": {
        "id": "mLpCANNabynC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "gPgmBHrsXkls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "YhCNIjFLYesy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO pip install torch and tensorflow"
      ],
      "metadata": {
        "id": "vRjLZvVOcDrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hBr_PvfPZIVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cuda is available : \",torch.cuda.is_available())\n",
        "print(\"Cuda is enabled   : \",torch.backends.cudnn.enabled)\n",
        "print(\"Cuda device name  : \",torch.cuda.get_device_name(0))\n",
        "print('   Mem Allocated  : ', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "print('   Mem Cached     : ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ],
      "metadata": {
        "id": "X_oxkOd6Z-Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "dev = torch.device(\"cuda\")\n",
        "t1 = torch.randn(1,2)\n",
        "t2 = torch.randn(1,2).to(dev)\n",
        "t1.to(dev)\n",
        "print(\"False:\",t1.is_cuda)\n",
        "t1 = t1.to(dev)\n",
        "print(\"True:\",t1.is_cuda)\n",
        "\n",
        "class M(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(1,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        return x\n",
        "model = M()\n",
        "model.to(dev)\n",
        "print(\"True:\",next(model.parameters()).is_cuda) # True"
      ],
      "metadata": {
        "id": "xVlsw4sSy3Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "i35-IT83aKHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "print(\"GPU is available  : \",tf.test.is_gpu_available())\n",
        "print(\"Device info       : \",tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "0oFJmF5eaQPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "    c = tf.matmul(a, b)\n",
        "    d = tf.matmul(b, a)\n",
        "print(c)\n",
        "print(\"\\n\")\n",
        "print(d)"
      ],
      "metadata": {
        "id": "LCAHS7pfbvtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "     def __init__(self):\n",
        "         super(MyModel, self).__init__()\n",
        "         self.flatten = tf.keras.layers.Flatten()\n",
        "         self.d1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "         self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "         self.d2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "     def call(self, x):\n",
        "         x = self.flatten(x)\n",
        "         x = self.d1(x)\n",
        "         x = self.dropout(x)\n",
        "         x = self.d2(x)\n",
        "         return x\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "model = MyModel()\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Y9GG_2yzpiG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Done"
      ],
      "metadata": {
        "id": "3WIauPsrdJGj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}